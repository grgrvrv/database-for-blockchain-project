# SQLç»„å®æ–½æŒ‡å— - PostgreSQLæ–¹æ¡ˆ



## ğŸ“‹ ä»»åŠ¡æ¸…å•

- [ ] Task 1: å®‰è£…PostgreSQLï¼ˆ30åˆ†é’Ÿï¼‰
- [ ] Task 2: åˆ›å»ºç®€åŒ–çš„æ•°æ®åº“Schemaï¼ˆ1å°æ—¶ï¼‰
- [ ] Task 3: åˆ›å»ºç´¢å¼•å’Œè§†å›¾ï¼ˆ30åˆ†é’Ÿï¼‰
- [ ] Task 4: ç¼–å†™æ•°æ®åŠ è½½è„šæœ¬ï¼ˆ2å°æ—¶ï¼‰
- [ ] Task 5: å®ç°5ä¸ªæŸ¥è¯¢ï¼ˆ2å°æ—¶ï¼‰
- [ ] Task 6: æ€§èƒ½ä¼˜åŒ–ï¼ˆ1å°æ—¶ï¼‰
- [ ] Task 7: æµ‹è¯•å’Œæ–‡æ¡£ï¼ˆ1å°æ—¶ï¼‰

---

## ğŸ› ï¸ Task 1: å®‰è£…PostgreSQL

### æ–¹æ³•1ï¼šDockerï¼ˆæ¨èï¼‰

```bash
# æ‹‰å–PostgreSQLé•œåƒ
docker pull postgres:15

# å¯åŠ¨å®¹å™¨
docker run -d \
  --name token-analyzer-postgres \
  -e POSTGRES_PASSWORD=yourpassword \
  -e POSTGRES_DB=token_analyzer \
  -p 5432:5432 \
  postgres:15

# éªŒè¯å®‰è£…
docker exec -it token-analyzer-postgres psql -U postgres -d token_analyzer -c "SELECT version();"
```

### æ–¹æ³•2ï¼šæœ¬åœ°å®‰è£…

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install postgresql postgresql-contrib

# macOS
brew install postgresql@15
brew services start postgresql@15

# åˆ›å»ºæ•°æ®åº“
createdb token_analyzer
```

---

## ğŸ“Š Task 2: åˆ›å»ºç®€åŒ–Schema

ä¿å­˜ä¸º `sql_schema_simplified.sql`:

```sql
-- ============================================================================
-- åŒºå—é“¾ä»£å¸åˆ†æç³»ç»Ÿ - ç®€åŒ–Schema (è¯¾ç¨‹é¡¹ç›®ç‰ˆæœ¬)
-- æ•°æ®åº“: PostgreSQL 14+
-- å®ä½“æ•°é‡: 7ä¸ªæ ¸å¿ƒè¡¨
-- ============================================================================

DROP TABLE IF EXISTS ALERT CASCADE;
DROP TABLE IF EXISTS PROJECT CASCADE;
DROP TABLE IF EXISTS TOKEN_SCORE CASCADE;
DROP TABLE IF EXISTS TOKEN_HOLDER CASCADE;
DROP TABLE IF EXISTS CEX_PRICE CASCADE;
DROP TABLE IF EXISTS DEX_PRICE CASCADE;
DROP TABLE IF EXISTS TOKEN CASCADE;

-- ============================================================================
-- 1. TOKENï¼ˆä»£å¸åŸºæœ¬ä¿¡æ¯ï¼‰
-- ============================================================================
CREATE TABLE TOKEN (
    token_address VARCHAR(42) PRIMARY KEY,
    symbol VARCHAR(20) NOT NULL,
    name VARCHAR(100) NOT NULL,
    chain VARCHAR(20) NOT NULL DEFAULT 'ETH',
    is_proxy BOOLEAN DEFAULT false,
    is_upgradeable BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_token_symbol ON TOKEN(symbol);
CREATE INDEX idx_token_risk ON TOKEN(is_proxy, is_upgradeable)
WHERE is_proxy = true OR is_upgradeable = true;

COMMENT ON TABLE TOKEN IS 'ä»£å¸åŸºæœ¬ä¿¡æ¯è¡¨';
COMMENT ON COLUMN TOKEN.is_proxy IS 'ä»£ç†åˆçº¦ï¼ˆé«˜é£é™©ï¼‰';
COMMENT ON COLUMN TOKEN.is_upgradeable IS 'å¯å‡çº§åˆçº¦ï¼ˆé«˜é£é™©ï¼‰';

-- ============================================================================
-- 2. DEX_PRICEï¼ˆDEXä»·æ ¼å¿«ç…§ - æ—¶åºæ•°æ®ï¼‰
-- ============================================================================
CREATE TABLE DEX_PRICE (
    price_id BIGSERIAL,
    token_address VARCHAR(42) NOT NULL,
    price DECIMAL(36, 18) NOT NULL,
    tvl DECIMAL(36, 2),
    liquidity_depth DECIMAL(36, 2),
    volume_24h DECIMAL(36, 2),
    timestamp TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,

    PRIMARY KEY (price_id, timestamp),
    CONSTRAINT fk_dex_token FOREIGN KEY (token_address) REFERENCES TOKEN(token_address)
) PARTITION BY RANGE (timestamp);

-- åˆ›å»ºåˆ†åŒºï¼ˆè¿‘3ä¸ªæœˆï¼‰
CREATE TABLE DEX_PRICE_2025_01 PARTITION OF DEX_PRICE
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE DEX_PRICE_2025_02 PARTITION OF DEX_PRICE
FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

CREATE TABLE DEX_PRICE_2025_03 PARTITION OF DEX_PRICE
FOR VALUES FROM ('2025-03-01') TO ('2025-04-01');

-- ç´¢å¼•
CREATE INDEX idx_dex_token_time ON DEX_PRICE(token_address, timestamp DESC);
CREATE INDEX idx_dex_time ON DEX_PRICE(timestamp DESC);

COMMENT ON TABLE DEX_PRICE IS 'DEXä»·æ ¼æ—¶åºæ•°æ®ï¼ˆæŒ‰æœˆåˆ†åŒºï¼‰';

-- ============================================================================
-- 3. CEX_PRICEï¼ˆCEXå¸‚åœºæ•°æ® - æ—¶åºæ•°æ®ï¼‰
-- ============================================================================
CREATE TABLE CEX_PRICE (
    price_id BIGSERIAL,
    token_symbol VARCHAR(20) NOT NULL,
    exchange VARCHAR(50) NOT NULL,
    spot_price DECIMAL(36, 18),
    funding_rate DECIMAL(10, 8),
    volume_24h DECIMAL(36, 2),
    timestamp TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,

    PRIMARY KEY (price_id, timestamp)
) PARTITION BY RANGE (timestamp);

-- åˆ›å»ºåˆ†åŒº
CREATE TABLE CEX_PRICE_2025_01 PARTITION OF CEX_PRICE
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE CEX_PRICE_2025_02 PARTITION OF CEX_PRICE
FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

CREATE TABLE CEX_PRICE_2025_03 PARTITION OF CEX_PRICE
FOR VALUES FROM ('2025-03-01') TO ('2025-04-01');

-- ç´¢å¼•
CREATE INDEX idx_cex_symbol_time ON CEX_PRICE(token_symbol, timestamp DESC);
CREATE INDEX idx_cex_exchange ON CEX_PRICE(exchange);

COMMENT ON TABLE CEX_PRICE IS 'CEXå¸‚åœºæ•°æ®ï¼ˆæŒ‰æœˆåˆ†åŒºï¼‰';

-- ============================================================================
-- 4. TOKEN_HOLDERï¼ˆæŒä»“åˆ†å¸ƒï¼‰
-- ============================================================================
CREATE TABLE TOKEN_HOLDER (
    holder_id BIGSERIAL PRIMARY KEY,
    token_address VARCHAR(42) NOT NULL,
    holder_address VARCHAR(42) NOT NULL,
    balance DECIMAL(78, 0) NOT NULL,
    percentage DECIMAL(10, 6) NOT NULL,
    rank INT NOT NULL,
    snapshot_date DATE NOT NULL DEFAULT CURRENT_DATE,

    CONSTRAINT fk_holder_token FOREIGN KEY (token_address) REFERENCES TOKEN(token_address),
    CONSTRAINT uq_holder_snapshot UNIQUE (token_address, holder_address, snapshot_date)
);

CREATE INDEX idx_holder_token_date ON TOKEN_HOLDER(token_address, snapshot_date DESC);
CREATE INDEX idx_holder_rank ON TOKEN_HOLDER(token_address, rank) WHERE rank <= 10;

COMMENT ON TABLE TOKEN_HOLDER IS 'ä»£å¸æŒä»“åˆ†å¸ƒå¿«ç…§';

-- ============================================================================
-- 5. TOKEN_SCOREï¼ˆä»£å¸è¯„åˆ†ï¼‰
-- ============================================================================
CREATE TABLE TOKEN_SCORE (
    score_id BIGSERIAL PRIMARY KEY,
    token_address VARCHAR(42) NOT NULL,
    score INT NOT NULL CHECK (score >= 0 AND score <= 100),
    score_factors JSONB,
    timestamp TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT fk_score_token FOREIGN KEY (token_address) REFERENCES TOKEN(token_address)
);

CREATE INDEX idx_score_token_time ON TOKEN_SCORE(token_address, timestamp DESC);
CREATE INDEX idx_score_value ON TOKEN_SCORE(score DESC);

COMMENT ON TABLE TOKEN_SCORE IS 'ä»£å¸ç»¼åˆè¯„åˆ†';

-- ============================================================================
-- 6. PROJECTï¼ˆé¡¹ç›®ä¿¡æ¯ï¼‰
-- ============================================================================
CREATE TABLE PROJECT (
    project_id SERIAL PRIMARY KEY,
    token_address VARCHAR(42) NOT NULL UNIQUE,
    project_name VARCHAR(100) NOT NULL,
    github_repo VARCHAR(200),
    github_stars INT DEFAULT 0,
    commit_count_7d INT DEFAULT 0,
    last_commit_at TIMESTAMP,

    CONSTRAINT fk_project_token FOREIGN KEY (token_address) REFERENCES TOKEN(token_address)
);

CREATE INDEX idx_project_token ON PROJECT(token_address);
CREATE INDEX idx_project_stars ON PROJECT(github_stars DESC);

COMMENT ON TABLE PROJECT IS 'é¡¹ç›®åŸºæœ¬ä¿¡æ¯å’ŒGitHubæ´»è·ƒåº¦';

-- ============================================================================
-- 7. ALERTï¼ˆé¢„è­¦è®°å½•ï¼‰
-- ============================================================================
CREATE TABLE ALERT (
    alert_id BIGSERIAL PRIMARY KEY,
    token_address VARCHAR(42) NOT NULL,
    alert_type VARCHAR(50) NOT NULL,
    severity VARCHAR(20) NOT NULL CHECK (severity IN ('LOW', 'MEDIUM', 'HIGH', 'CRITICAL')),
    message TEXT,
    timestamp TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT fk_alert_token FOREIGN KEY (token_address) REFERENCES TOKEN(token_address)
);

CREATE INDEX idx_alert_token_time ON ALERT(token_address, timestamp DESC);
CREATE INDEX idx_alert_severity ON ALERT(severity, timestamp DESC) WHERE severity IN ('HIGH', 'CRITICAL');

COMMENT ON TABLE ALERT IS 'é£é™©é¢„è­¦è®°å½•';

-- ============================================================================
-- è§†å›¾: ä»£å¸ä»ªè¡¨ç›˜
-- ============================================================================
CREATE OR REPLACE VIEW v_token_dashboard AS
SELECT
    t.token_address,
    t.symbol,
    t.name,
    t.is_proxy,
    t.is_upgradeable,
    d.price as latest_dex_price,
    d.tvl,
    d.volume_24h,
    s.score as latest_score,
    p.github_stars,
    p.commit_count_7d
FROM TOKEN t
LEFT JOIN LATERAL (
    SELECT price, tvl, volume_24h
    FROM DEX_PRICE
    WHERE token_address = t.token_address
    ORDER BY timestamp DESC
    LIMIT 1
) d ON true
LEFT JOIN LATERAL (
    SELECT score
    FROM TOKEN_SCORE
    WHERE token_address = t.token_address
    ORDER BY timestamp DESC
    LIMIT 1
) s ON true
LEFT JOIN PROJECT p ON t.token_address = p.token_address;

COMMENT ON VIEW v_token_dashboard IS 'ä»£å¸ç»¼åˆä»ªè¡¨ç›˜è§†å›¾';

-- ============================================================================
-- åˆå§‹åŒ–ç¤ºä¾‹æ•°æ®
-- ============================================================================
INSERT INTO TOKEN (token_address, symbol, name, is_proxy, is_upgradeable)
VALUES
    ('0x0000000000000000000000000000000000000001', 'ETH', 'Ethereum', false, false),
    ('0xdAC17F958D2ee523a2206206994597C13D831ec7', 'USDT', 'Tether USD', true, false),
    ('0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48', 'USDC', 'USD Coin', true, true)
ON CONFLICT (token_address) DO NOTHING;

-- ============================================================================
-- å®Œæˆ
-- ============================================================================
SELECT 'Schemaåˆ›å»ºå®Œæˆï¼å…±7ä¸ªè¡¨' as message;
```

æ‰§è¡ŒSchema:

```bash
# ä½¿ç”¨Docker
docker exec -i token-analyzer-postgres psql -U postgres -d token_analyzer < sql_schema_simplified.sql

# æœ¬åœ°å®‰è£…
psql -U postgres -d token_analyzer -f sql_schema_simplified.sql
```

---

## ğŸ Task 4: æ•°æ®åŠ è½½è„šæœ¬

åˆ›å»º `sql_data_loader.py`:

```python
import psycopg2
from psycopg2.extras import execute_batch
from datetime import datetime, timedelta
import random
from faker import Faker

fake = Faker()

# æ•°æ®åº“è¿æ¥
conn = psycopg2.connect(
    host="localhost",
    port=5432,
    database="token_analyzer",
    user="postgres",
    password="yourpassword"
)
cur = conn.cursor()

print("å¼€å§‹ç”Ÿæˆæ•°æ®...")

# 1. ç”Ÿæˆ100ä¸ªä»£å¸
print("ç”ŸæˆTOKENæ•°æ®...")
tokens = []
for i in range(100):
    tokens.append((
        f"0x{fake.hexify(text='^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^')}",
        fake.cryptocurrency_code(),
        fake.cryptocurrency_name(),
        'ETH',
        random.choice([True, False]),
        random.choice([True, False])
    ))

execute_batch(cur, """
    INSERT INTO TOKEN (token_address, symbol, name, chain, is_proxy, is_upgradeable)
    VALUES (%s, %s, %s, %s, %s, %s)
    ON CONFLICT (token_address) DO NOTHING
""", tokens)

print(f"âœ“ æ’å…¥äº† {len(tokens)} ä¸ªä»£å¸")

# è·å–æ‰€æœ‰token_address
cur.execute("SELECT token_address, symbol FROM TOKEN")
token_list = cur.fetchall()

# 2. ç”ŸæˆDEXä»·æ ¼æ•°æ®ï¼ˆæ¯ä¸ªä»£å¸1000æ¡è®°å½• = 10ä¸‡æ¡ï¼‰
print("ç”ŸæˆDEX_PRICEæ•°æ®ï¼ˆè¿™ä¼šèŠ±å‡ åˆ†é’Ÿï¼‰...")
dex_prices = []
for token_address, symbol in token_list:
    base_price = random.uniform(0.1, 10000)
    for i in range(1000):
        timestamp = datetime.now() - timedelta(minutes=i)
        price = base_price * (1 + random.uniform(-0.05, 0.05))
        dex_prices.append((
            token_address,
            price,
            random.uniform(100000, 10000000),  # TVL
            random.uniform(50000, 5000000),    # liquidity_depth
            random.uniform(10000, 1000000),    # volume_24h
            timestamp
        ))

# æ‰¹é‡æ’å…¥ï¼ˆæ¯æ¬¡1000æ¡ï¼‰
batch_size = 1000
for i in range(0, len(dex_prices), batch_size):
    batch = dex_prices[i:i+batch_size]
    execute_batch(cur, """
        INSERT INTO DEX_PRICE (token_address, price, tvl, liquidity_depth, volume_24h, timestamp)
        VALUES (%s, %s, %s, %s, %s, %s)
    """, batch)
    if (i // batch_size) % 10 == 0:
        print(f"  å·²æ’å…¥ {i + len(batch)} / {len(dex_prices)} æ¡DEXä»·æ ¼...")

print(f"âœ“ æ’å…¥äº† {len(dex_prices)} æ¡DEXä»·æ ¼æ•°æ®")

# 3. ç”ŸæˆCEXä»·æ ¼æ•°æ®
print("ç”ŸæˆCEX_PRICEæ•°æ®...")
exchanges = ['Binance', 'OKX', 'Coinbase', 'Bybit']
cex_prices = []
for token_address, symbol in token_list[:50]:  # åªä¸ºå‰50ä¸ªä»£å¸ç”ŸæˆCEXæ•°æ®
    for i in range(500):
        timestamp = datetime.now() - timedelta(minutes=i*2)
        cex_prices.append((
            symbol,
            random.choice(exchanges),
            random.uniform(0.1, 10000),
            random.uniform(-0.0001, 0.0001),
            random.uniform(10000, 1000000),
            timestamp
        ))

execute_batch(cur, """
    INSERT INTO CEX_PRICE (token_symbol, exchange, spot_price, funding_rate, volume_24h, timestamp)
    VALUES (%s, %s, %s, %s, %s, %s)
""", cex_prices, page_size=1000)

print(f"âœ“ æ’å…¥äº† {len(cex_prices)} æ¡CEXä»·æ ¼æ•°æ®")

# 4. ç”ŸæˆæŒä»“æ•°æ®
print("ç”ŸæˆTOKEN_HOLDERæ•°æ®...")
holders = []
for token_address, symbol in token_list:
    # æ¯ä¸ªä»£å¸ç”Ÿæˆ20ä¸ªæŒä»“åœ°å€
    for rank in range(1, 21):
        holders.append((
            token_address,
            f"0x{fake.hexify(text='^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^')}",
            random.randint(1000000, 100000000),
            random.uniform(0.5, 20.0),
            rank,
            datetime.now().date()
        ))

execute_batch(cur, """
    INSERT INTO TOKEN_HOLDER (token_address, holder_address, balance, percentage, rank, snapshot_date)
    VALUES (%s, %s, %s, %s, %s, %s)
    ON CONFLICT DO NOTHING
""", holders, page_size=1000)

print(f"âœ“ æ’å…¥äº† {len(holders)} æ¡æŒä»“æ•°æ®")

# 5. ç”Ÿæˆè¯„åˆ†æ•°æ®
print("ç”ŸæˆTOKEN_SCOREæ•°æ®...")
scores = []
for token_address, symbol in token_list:
    for i in range(10):
        timestamp = datetime.now() - timedelta(hours=i*24)
        scores.append((
            token_address,
            random.randint(30, 95),
            {
                "liquidity_score": random.randint(50, 100),
                "holder_score": random.randint(40, 90),
                "dev_score": random.randint(30, 80)
            },
            timestamp
        ))

execute_batch(cur, """
    INSERT INTO TOKEN_SCORE (token_address, score, score_factors, timestamp)
    VALUES (%s, %s, %s::jsonb, %s)
""", [(t, s, str(f).replace("'", '"'), ts) for t, s, f, ts in scores])

print(f"âœ“ æ’å…¥äº† {len(scores)} æ¡è¯„åˆ†æ•°æ®")

# 6. ç”Ÿæˆé¡¹ç›®æ•°æ®
print("ç”ŸæˆPROJECTæ•°æ®...")
projects = []
for token_address, symbol in token_list[:80]:  # 80%çš„ä»£å¸æœ‰é¡¹ç›®ä¿¡æ¯
    projects.append((
        token_address,
        f"{symbol} Project",
        f"https://github.com/{fake.user_name()}/{symbol.lower()}",
        random.randint(10, 10000),
        random.randint(0, 100),
        datetime.now() - timedelta(days=random.randint(0, 30))
    ))

execute_batch(cur, """
    INSERT INTO PROJECT (token_address, project_name, github_repo, github_stars, commit_count_7d, last_commit_at)
    VALUES (%s, %s, %s, %s, %s, %s)
    ON CONFLICT (token_address) DO NOTHING
""", projects)

print(f"âœ“ æ’å…¥äº† {len(projects)} ä¸ªé¡¹ç›®")

# 7. ç”Ÿæˆé¢„è­¦æ•°æ®
print("ç”ŸæˆALERTæ•°æ®...")
alert_types = ['LIQUIDITY_DROP', 'PRICE_SPIKE', 'WHALE_MOVEMENT', 'RUG_PULL_RISK']
severities = ['LOW', 'MEDIUM', 'HIGH', 'CRITICAL']
alerts = []
for token_address, symbol in random.sample(token_list, 30):
    for i in range(5):
        alerts.append((
            token_address,
            random.choice(alert_types),
            random.choice(severities),
            f"Alert for {symbol}: {fake.sentence()}",
            datetime.now() - timedelta(hours=i*6)
        ))

execute_batch(cur, """
    INSERT INTO ALERT (token_address, alert_type, severity, message, timestamp)
    VALUES (%s, %s, %s, %s, %s)
""", alerts)

print(f"âœ“ æ’å…¥äº† {len(alerts)} æ¡é¢„è­¦")

conn.commit()
cur.close()
conn.close()

print("\nâœ… æ•°æ®åŠ è½½å®Œæˆï¼")
print(f"æ€»è®¡:")
print(f"  - {len(tokens)} ä¸ªä»£å¸")
print(f"  - {len(dex_prices)} æ¡DEXä»·æ ¼è®°å½•")
print(f"  - {len(cex_prices)} æ¡CEXä»·æ ¼è®°å½•")
print(f"  - {len(holders)} æ¡æŒä»“è®°å½•")
print(f"  - {len(scores)} æ¡è¯„åˆ†è®°å½•")
print(f"  - {len(projects)} ä¸ªé¡¹ç›®")
print(f"  - {len(alerts)} æ¡é¢„è­¦")
```

å®‰è£…ä¾èµ–å¹¶è¿è¡Œ:

```bash
pip install psycopg2-binary faker

python sql_data_loader.py
```

---

## ğŸ“ Task 5: å®ç°5ä¸ªæŸ¥è¯¢

åˆ›å»º `sql_queries.py`:

```python
import psycopg2
import time

conn = psycopg2.connect(
    host="localhost",
    port=5432,
    database="token_analyzer",
    user="postgres",
    password="yourpassword"
)

def benchmark_query(name, query, params=None, iterations=100):
    """æ‰§è¡ŒæŸ¥è¯¢å¹¶æµ‹é‡æ€§èƒ½"""
    cur = conn.cursor()

    # é¢„çƒ­
    cur.execute(query, params)
    cur.fetchall()

    # æ­£å¼æµ‹è¯•
    latencies = []
    for _ in range(iterations):
        start = time.time()
        cur.execute(query, params)
        results = cur.fetchall()
        latency = (time.time() - start) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        latencies.append(latency)

    cur.close()

    avg_latency = sum(latencies) / len(latencies)
    p95_latency = sorted(latencies)[int(len(latencies) * 0.95)]

    print(f"\n{name}")
    print(f"  å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")
    print(f"  P95å»¶è¿Ÿ: {p95_latency:.2f}ms")
    print(f"  è¿”å›è¡Œæ•°: {len(results)}")

    return avg_latency, p95_latency

# ============================================================================
# Q1: ç‚¹æŸ¥è¯¢ - è·å–å•ä¸ªä»£å¸æœ€æ–°ä¿¡æ¯
# ============================================================================
q1_query = """
SELECT
    t.symbol,
    t.name,
    d.price as latest_price,
    d.tvl,
    s.score
FROM TOKEN t
LEFT JOIN LATERAL (
    SELECT price, tvl
    FROM DEX_PRICE
    WHERE token_address = t.token_address
    ORDER BY timestamp DESC
    LIMIT 1
) d ON true
LEFT JOIN LATERAL (
    SELECT score
    FROM TOKEN_SCORE
    WHERE token_address = t.token_address
    ORDER BY timestamp DESC
    LIMIT 1
) s ON true
WHERE t.token_address = %s;
"""

# è·å–ä¸€ä¸ªç¤ºä¾‹tokenåœ°å€
cur = conn.cursor()
cur.execute("SELECT token_address FROM TOKEN LIMIT 1")
sample_token = cur.fetchone()[0]
cur.close()

benchmark_query("Q1: ç‚¹æŸ¥è¯¢ (å•ä¸ªä»£å¸ä¿¡æ¯)", q1_query, (sample_token,))

# ============================================================================
# Q2: èŒƒå›´æŸ¥è¯¢ - ä»·æ ¼å†å²èµ°åŠ¿
# ============================================================================
q2_query = """
SELECT timestamp, price, tvl
FROM DEX_PRICE
WHERE token_address = %s
  AND timestamp > NOW() - INTERVAL '24 hours'
ORDER BY timestamp DESC;
"""

benchmark_query("Q2: èŒƒå›´æŸ¥è¯¢ (24å°æ—¶ä»·æ ¼èµ°åŠ¿)", q2_query, (sample_token,))

# ============================================================================
# Q3: èšåˆæŸ¥è¯¢ - Top 10é«˜è¯„åˆ†ä»£å¸
# ============================================================================
q3_query = """
SELECT
    t.symbol,
    s.score,
    d.tvl
FROM TOKEN t
JOIN LATERAL (
    SELECT score
    FROM TOKEN_SCORE
    WHERE token_address = t.token_address
    ORDER BY timestamp DESC
    LIMIT 1
) s ON true
LEFT JOIN LATERAL (
    SELECT tvl
    FROM DEX_PRICE
    WHERE token_address = t.token_address
    ORDER BY timestamp DESC
    LIMIT 1
) d ON true
ORDER BY s.score DESC
LIMIT 10;
"""

benchmark_query("Q3: èšåˆæŸ¥è¯¢ (Top 10é«˜è¯„åˆ†ä»£å¸)", q3_query)

# ============================================================================
# Q4: å¤æ‚JOIN - æŒä»“é›†ä¸­åº¦åˆ†æ
# ============================================================================
q4_query = """
SELECT
    t.symbol,
    SUM(CASE WHEN h.rank <= 10 THEN h.percentage ELSE 0 END) as top10_concentration
FROM TOKEN t
JOIN TOKEN_HOLDER h ON t.token_address = h.token_address
WHERE h.snapshot_date = CURRENT_DATE
GROUP BY t.symbol, t.token_address
HAVING SUM(CASE WHEN h.rank <= 10 THEN h.percentage ELSE 0 END) > 30
ORDER BY top10_concentration DESC;
"""

benchmark_query("Q4: å¤æ‚JOIN (æŒä»“é›†ä¸­åº¦åˆ†æ)", q4_query, iterations=50)

# ============================================================================
# Q5: å†™å…¥æµ‹è¯• - æ‰¹é‡æ’å…¥ä»·æ ¼æ•°æ®
# ============================================================================
print("\nQ5: æ‰¹é‡å†™å…¥æµ‹è¯• (æ’å…¥1000æ¡ä»·æ ¼è®°å½•)")

cur = conn.cursor()

# å‡†å¤‡æ•°æ®
from datetime import datetime
test_data = [(sample_token, 100.0 + i*0.1, 1000000.0, 500000.0, 100000.0, datetime.now())
             for i in range(1000)]

start = time.time()
cur.executemany("""
    INSERT INTO DEX_PRICE (token_address, price, tvl, liquidity_depth, volume_24h, timestamp)
    VALUES (%s, %s, %s, %s, %s, %s)
""", test_data)
conn.commit()
write_time = (time.time() - start) * 1000

cur.close()

print(f"  æ‰¹é‡æ’å…¥1000æ¡: {write_time:.2f}ms")
print(f"  å¹³å‡æ¯æ¡: {write_time/1000:.2f}ms")

conn.close()

print("\nâœ… SQLæŸ¥è¯¢æµ‹è¯•å®Œæˆï¼")
```

è¿è¡Œæµ‹è¯•:

```bash
python sql_queries.py
```

---

## ğŸ“Š Task 6: æ€§èƒ½ä¼˜åŒ–

### æ£€æŸ¥å’Œåˆ›å»ºç¼ºå¤±çš„ç´¢å¼•

```sql
-- æ£€æŸ¥æ…¢æŸ¥è¯¢
SELECT query, mean_exec_time, calls
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;

-- æ·»åŠ é¢å¤–çš„å¤åˆç´¢å¼•ï¼ˆå¦‚æœéœ€è¦ï¼‰
CREATE INDEX idx_dex_price_token_ts_price ON DEX_PRICE(token_address, timestamp DESC, price);

-- åˆ†æè¡¨ç»Ÿè®¡ä¿¡æ¯
ANALYZE TOKEN;
ANALYZE DEX_PRICE;
ANALYZE TOKEN_SCORE;
```

### EXPLAINåˆ†æ

```sql
-- åˆ†ææŸ¥è¯¢è®¡åˆ’
EXPLAIN (ANALYZE, BUFFERS)
SELECT ...ï¼ˆä½ çš„æŸ¥è¯¢ï¼‰;
```

---

## ğŸ“„ Task 7: æ–‡æ¡£å’Œäº¤ä»˜

åˆ›å»º `SQL_README.md`:

```markdown
# SQLæ–¹æ¡ˆå®ç°è¯´æ˜

## æ•°æ®åº“é…ç½®
- **æ•°æ®åº“**: PostgreSQL 15
- **æ•°æ®è§„æ¨¡**:
  - 100ä¸ªä»£å¸
  - 10ä¸‡æ¡ä»·æ ¼è®°å½•
  - 2000æ¡æŒä»“è®°å½•
- **åˆ†åŒºç­–ç•¥**: æŒ‰æœˆåˆ†åŒºï¼ˆDEX_PRICE, CEX_PRICEï¼‰

## Schemaè®¾è®¡è¦ç‚¹
1. **æ—¶åºæ•°æ®åˆ†åŒº**: ä»·æ ¼è¡¨æŒ‰æœˆåˆ†åŒºï¼Œæé«˜æŸ¥è¯¢æ€§èƒ½
2. **ç´¢å¼•ä¼˜åŒ–**: ä¸ºå¸¸ç”¨æŸ¥è¯¢åˆ›å»ºå¤åˆç´¢å¼•
3. **LATERAL JOIN**: ä½¿ç”¨PostgreSQLç‰¹æ€§ä¼˜åŒ–å­æŸ¥è¯¢

## æ€§èƒ½æµ‹è¯•ç»“æœ

| æŸ¥è¯¢ | å¹³å‡å»¶è¿Ÿ | P95å»¶è¿Ÿ |
|------|---------|---------|
| Q1 ç‚¹æŸ¥è¯¢ | XX ms | XX ms |
| Q2 èŒƒå›´æŸ¥è¯¢ | XX ms | XX ms |
| Q3 èšåˆæŸ¥è¯¢ | XX ms | XX ms |
| Q4 å¤æ‚JOIN | XX ms | XX ms |
| Q5 æ‰¹é‡å†™å…¥ | XX ms/1000æ¡ | - |

## æ–‡ä»¶æ¸…å•
- `sql_schema_simplified.sql` - å»ºè¡¨è„šæœ¬
- `sql_data_loader.py` - æ•°æ®åŠ è½½è„šæœ¬
- `sql_queries.py` - æŸ¥è¯¢æµ‹è¯•è„šæœ¬
```

---

## âœ… äº¤ä»˜æ£€æŸ¥æ¸…å•

å®Œæˆåç¡®è®¤ï¼š

- [ ] PostgreSQLå·²å®‰è£…å¹¶è¿è¡Œ
- [ ] 7ä¸ªè¡¨åˆ›å»ºæˆåŠŸ
- [ ] æ•°æ®åŠ è½½æˆåŠŸï¼ˆ100ä¸ªä»£å¸ï¼Œ10ä¸‡+æ¡è®°å½•ï¼‰
- [ ] 5ä¸ªæŸ¥è¯¢éƒ½èƒ½æ­£å¸¸æ‰§è¡Œ
- [ ] è®°å½•äº†æ€§èƒ½æ•°æ®ï¼ˆå»¶è¿Ÿã€ååé‡ï¼‰
- [ ] æ–‡æ¡£å®Œæ•´

---

## ğŸ†˜ å¸¸è§é—®é¢˜

### Q: psycopg2å®‰è£…å¤±è´¥ï¼Ÿ
A: ä½¿ç”¨äºŒè¿›åˆ¶ç‰ˆæœ¬ï¼š`pip install psycopg2-binary`

### Q: åˆ†åŒºè¡¨æ’å…¥å¤±è´¥ï¼Ÿ
A: ç¡®ä¿timestampåœ¨åˆ†åŒºèŒƒå›´å†…ï¼Œæˆ–åˆ›å»ºæ›´å¤šåˆ†åŒº

### Q: æŸ¥è¯¢å¤ªæ…¢ï¼Ÿ
A: è¿è¡Œ `ANALYZE` æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼Œæ£€æŸ¥ç´¢å¼•æ˜¯å¦ç”Ÿæ•ˆ

### Q: è¿æ¥æ•°æ®åº“å¤±è´¥ï¼Ÿ
A: æ£€æŸ¥ç«¯å£ã€å¯†ç ï¼Œç¡®è®¤Dockerå®¹å™¨æ­£åœ¨è¿è¡Œ

---

**å®Œæˆæ—¶é—´**: Day 1-2ï¼Œå…±8å°æ—¶
**ä¸‹ä¸€æ­¥**: å°†æ€§èƒ½æ•°æ®äº¤ç»™å®éªŒç»„ç”¨äºå¯¹æ¯”åˆ†æ
