# å®éªŒç»„å®æ–½æŒ‡å— - æ€§èƒ½æµ‹è¯•ä¸æŠ¥å‘Šæ’°å†™


## ğŸ§ª Task 1: è®¾è®¡æµ‹è¯•æ¡†æ¶

åˆ›å»º `benchmark_framework.py`:

```python
import time
import psycopg2
from pymongo import MongoClient
import redis
import json
from datetime import datetime
import matplotlib.pyplot as plt
import pandas as pd

class DatabaseBenchmark:
    def __init__(self):
        # SQLè¿æ¥
        self.pg_conn = psycopg2.connect(
            host="localhost",
            port=5432,
            database="token_analyzer",
            user="postgres",
            password="yourpassword"
        )

        # NoSQLè¿æ¥
        self.mongo_client = MongoClient("mongodb://admin:yourpassword@localhost:27017/")
        self.mongo_db = self.mongo_client["token_analyzer"]
        self.redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)

        self.results = []

    def run_benchmark(self, name, sql_query, nosql_query, iterations=100):
        """
        å¯¹æ¯”SQLå’ŒNoSQLæŸ¥è¯¢æ€§èƒ½

        Args:
            name: æµ‹è¯•åç§°
            sql_query: SQLæŸ¥è¯¢å‡½æ•°
            nosql_query: NoSQLæŸ¥è¯¢å‡½æ•°
            iterations: è¿­ä»£æ¬¡æ•°
        """
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•: {name}")
        print(f"{'='*60}")

        # æµ‹è¯•SQL
        sql_latencies = []
        for i in range(iterations):
            start = time.time()
            sql_result = sql_query()
            latency = (time.time() - start) * 1000
            sql_latencies.append(latency)

            if i % 20 == 0:
                print(f"  SQLè¿›åº¦: {i}/{iterations}")

        sql_avg = sum(sql_latencies) / len(sql_latencies)
        sql_p95 = sorted(sql_latencies)[int(len(sql_latencies) * 0.95)]
        sql_p99 = sorted(sql_latencies)[int(len(sql_latencies) * 0.99)]

        # æµ‹è¯•NoSQL
        nosql_latencies = []
        for i in range(iterations):
            start = time.time()
            nosql_result = nosql_query()
            latency = (time.time() - start) * 1000
            nosql_latencies.append(latency)

            if i % 20 == 0:
                print(f"  NoSQLè¿›åº¦: {i}/{iterations}")

        nosql_avg = sum(nosql_latencies) / len(nosql_latencies)
        nosql_p95 = sorted(nosql_latencies)[int(len(nosql_latencies) * 0.95)]
        nosql_p99 = sorted(nosql_latencies)[int(len(nosql_latencies) * 0.99)]

        # è®°å½•ç»“æœ
        result = {
            "test_name": name,
            "sql_avg_ms": round(sql_avg, 2),
            "sql_p95_ms": round(sql_p95, 2),
            "sql_p99_ms": round(sql_p99, 2),
            "nosql_avg_ms": round(nosql_avg, 2),
            "nosql_p95_ms": round(nosql_p95, 2),
            "nosql_p99_ms": round(nosql_p99, 2),
            "sql_qps": round(1000 / sql_avg, 2),
            "nosql_qps": round(1000 / nosql_avg, 2),
            "winner": "SQL" if sql_avg < nosql_avg else "NoSQL",
            "speedup": round(max(sql_avg, nosql_avg) / min(sql_avg, nosql_avg), 2)
        }

        self.results.append(result)

        # æ‰“å°ç»“æœ
        print(f"\nSQLç»“æœ:")
        print(f"  å¹³å‡å»¶è¿Ÿ: {result['sql_avg_ms']}ms")
        print(f"  P95å»¶è¿Ÿ: {result['sql_p95_ms']}ms")
        print(f"  ååé‡: {result['sql_qps']} QPS")

        print(f"\nNoSQLç»“æœ:")
        print(f"  å¹³å‡å»¶è¿Ÿ: {result['nosql_avg_ms']}ms")
        print(f"  P95å»¶è¿Ÿ: {result['nosql_p95_ms']}ms")
        print(f"  ååé‡: {result['nosql_qps']} QPS")

        print(f"\nğŸ† èµ¢å®¶: {result['winner']} (å¿« {result['speedup']}x)")

        return result

    def generate_report(self, output_file="benchmark_results.md"):
        """ç”ŸæˆMarkdownæ ¼å¼çš„æµ‹è¯•æŠ¥å‘Š"""
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# SQL vs NoSQL æ€§èƒ½å¯¹æ¯”æµ‹è¯•æŠ¥å‘Š\n\n")
            f.write(f"**æµ‹è¯•æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            f.write("## æµ‹è¯•ç»“æœæ±‡æ€»\n\n")
            f.write("| æµ‹è¯•åœºæ™¯ | SQLå¹³å‡å»¶è¿Ÿ(ms) | NoSQLå¹³å‡å»¶è¿Ÿ(ms) | SQLååé‡(QPS) | NoSQLååé‡(QPS) | èµ¢å®¶ | æ€§èƒ½æå‡ |\n")
            f.write("|---------|-----------------|-------------------|----------------|------------------|------|----------|\n")

            for result in self.results:
                f.write(f"| {result['test_name']} | {result['sql_avg_ms']} | {result['nosql_avg_ms']} | "
                       f"{result['sql_qps']} | {result['nosql_qps']} | {result['winner']} | {result['speedup']}x |\n")

            f.write("\n## è¯¦ç»†åˆ†æ\n\n")
            for result in self.results:
                f.write(f"### {result['test_name']}\n\n")
                f.write(f"**SQLæ€§èƒ½**:\n")
                f.write(f"- å¹³å‡å»¶è¿Ÿ: {result['sql_avg_ms']}ms\n")
                f.write(f"- P95å»¶è¿Ÿ: {result['sql_p95_ms']}ms\n")
                f.write(f"- P99å»¶è¿Ÿ: {result['sql_p99_ms']}ms\n")
                f.write(f"- ååé‡: {result['sql_qps']} QPS\n\n")

                f.write(f"**NoSQLæ€§èƒ½**:\n")
                f.write(f"- å¹³å‡å»¶è¿Ÿ: {result['nosql_avg_ms']}ms\n")
                f.write(f"- P95å»¶è¿Ÿ: {result['nosql_p95_ms']}ms\n")
                f.write(f"- P99å»¶è¿Ÿ: {result['nosql_p99_ms']}ms\n")
                f.write(f"- ååé‡: {result['nosql_qps']} QPS\n\n")

                f.write(f"**ç»“è®º**: {result['winner']} åœ¨æ­¤åœºæ™¯ä¸‹æ€§èƒ½æ›´ä¼˜ï¼Œå¿« {result['speedup']}å€\n\n")

        print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")

    def plot_results(self):
        """ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
        df = pd.DataFrame(self.results)

        # 1. å»¶è¿Ÿå¯¹æ¯”æŸ±çŠ¶å›¾
        fig, ax = plt.subplots(figsize=(12, 6))
        x = range(len(df))
        width = 0.35

        ax.bar([i - width/2 for i in x], df['sql_avg_ms'], width, label='SQL', color='#3498db')
        ax.bar([i + width/2 for i in x], df['nosql_avg_ms'], width, label='NoSQL', color='#e74c3c')

        ax.set_xlabel('æŸ¥è¯¢åœºæ™¯', fontsize=12)
        ax.set_ylabel('å¹³å‡å»¶è¿Ÿ (ms)', fontsize=12)
        ax.set_title('SQL vs NoSQL å¹³å‡å»¶è¿Ÿå¯¹æ¯”', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(df['test_name'], rotation=45, ha='right')
        ax.legend()
        ax.grid(axis='y', alpha=0.3)

        plt.tight_layout()
        plt.savefig('latency_comparison.png', dpi=300)
        print("âœ“ å»¶è¿Ÿå¯¹æ¯”å›¾å·²ä¿å­˜: latency_comparison.png")

        # 2. ååé‡å¯¹æ¯”æŸ±çŠ¶å›¾
        fig, ax = plt.subplots(figsize=(12, 6))

        ax.bar([i - width/2 for i in x], df['sql_qps'], width, label='SQL', color='#3498db')
        ax.bar([i + width/2 for i in x], df['nosql_qps'], width, label='NoSQL', color='#e74c3c')

        ax.set_xlabel('æŸ¥è¯¢åœºæ™¯', fontsize=12)
        ax.set_ylabel('ååé‡ (QPS)', fontsize=12)
        ax.set_title('SQL vs NoSQL ååé‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(df['test_name'], rotation=45, ha='right')
        ax.legend()
        ax.grid(axis='y', alpha=0.3)

        plt.tight_layout()
        plt.savefig('throughput_comparison.png', dpi=300)
        print("âœ“ ååé‡å¯¹æ¯”å›¾å·²ä¿å­˜: throughput_comparison.png")

        plt.close('all')

    def cleanup(self):
        """æ¸…ç†è¿æ¥"""
        self.pg_conn.close()
        self.mongo_client.close()
```

---

## ğŸ² Task 2: æ•°æ®ç”Ÿæˆå™¨

æ•°æ®ç”Ÿæˆå™¨å·²ç»ç”±SQLç»„å’ŒNoSQLç»„å®ç°ã€‚ä½ ä»¬éœ€è¦ç¡®è®¤ï¼š
1. ä¸¤è¾¹çš„æ•°æ®è§„æ¨¡ä¸€è‡´ï¼ˆ100ä¸ªä»£å¸ï¼Œ10ä¸‡æ¡ä»·æ ¼è®°å½•ï¼‰
2. æ•°æ®åˆ†å¸ƒç›¸ä¼¼ï¼ˆä»·æ ¼èŒƒå›´ã€æ—¶é—´èŒƒå›´ç­‰ï¼‰

éªŒè¯è„šæœ¬ `validate_data.py`:

```python
import psycopg2
from pymongo import MongoClient

# è¿æ¥æ•°æ®åº“
pg_conn = psycopg2.connect(
    host="localhost", port=5432,
    database="token_analyzer",
    user="postgres", password="yourpassword"
)
pg_cur = pg_conn.cursor()

mongo_client = MongoClient("mongodb://admin:yourpassword@localhost:27017/")
mongo_db = mongo_client["token_analyzer"]

print("æ•°æ®è§„æ¨¡éªŒè¯")
print("="*50)

# éªŒè¯ä»£å¸æ•°é‡
pg_cur.execute("SELECT COUNT(*) FROM TOKEN")
sql_tokens = pg_cur.fetchone()[0]
nosql_tokens = mongo_db.tokens.count_documents({})
print(f"ä»£å¸æ•°é‡ - SQL: {sql_tokens}, NoSQL: {nosql_tokens}")

# éªŒè¯ä»·æ ¼è®°å½•æ•°
pg_cur.execute("SELECT COUNT(*) FROM DEX_PRICE")
sql_prices = pg_cur.fetchone()[0]
nosql_prices = mongo_db.dex_prices.count_documents({})
print(f"DEXä»·æ ¼è®°å½• - SQL: {sql_prices}, NoSQL: {nosql_prices}")

# éªŒè¯æŒä»“è®°å½•æ•°
pg_cur.execute("SELECT COUNT(*) FROM TOKEN_HOLDER")
sql_holders = pg_cur.fetchone()[0]
nosql_holders = mongo_db.token_holders.count_documents({})
print(f"æŒä»“è®°å½• - SQL: {sql_holders}, NoSQL: {nosql_holders}")

# éªŒè¯å­˜å‚¨ç©ºé—´
pg_cur.execute("""
    SELECT pg_size_pretty(pg_database_size('token_analyzer'))
""")
sql_size = pg_cur.fetchone()[0]

mongo_stats = mongo_db.command("dbstats")
nosql_size_mb = mongo_stats['dataSize'] / (1024 * 1024)

print(f"å­˜å‚¨ç©ºé—´ - SQL: {sql_size}, NoSQL: {nosql_size_mb:.2f} MB")

print("\nâœ… æ•°æ®éªŒè¯å®Œæˆ")

pg_conn.close()
mongo_client.close()
```

---

## ğŸ“š Task 3: æŸ¥æ‰¾å­¦æœ¯æ–‡çŒ®

### æ¨èçš„æ–‡çŒ®æœç´¢æ¥æº

1. **Google Scholar** (https://scholar.google.com)
2. **IEEE Xplore** (https://ieeexplore.ieee.org)
3. **ACM Digital Library** (https://dl.acm.org)
4. **arXiv** (https://arxiv.org) - é¢„å°æœ¬

### æœç´¢å…³é”®è¯

ç»„åˆä½¿ç”¨ä»¥ä¸‹å…³é”®è¯ï¼š
- `blockchain data analytics`
- `cryptocurrency database`
- `SQL vs NoSQL performance`
- `time-series database blockchain`
- `nosql document database comparison`
- `polyglot persistence`

### å¿…é¡»å¼•ç”¨çš„æ–‡çŒ®ç±»å‹

1. **SQL vs NoSQLå¯¹æ¯”** (è‡³å°‘1ç¯‡)
2. **åŒºå—é“¾æ•°æ®åˆ†æ** (è‡³å°‘1ç¯‡)
3. **æ—¶åºæ•°æ®åº“ä¼˜åŒ–** (è‡³å°‘1ç¯‡)

### APAå¼•ç”¨æ ¼å¼ç¤ºä¾‹

```
ä½œè€…å§“, åé¦–å­—æ¯. (å¹´ä»½). æ–‡ç« æ ‡é¢˜. æœŸåˆŠåç§°, å·å·(æœŸå·), é¡µç . DOI

Cattell, R. (2011). Scalable SQL and NoSQL data stores. ACM SIGMOD Record, 39(4), 12-27. https://doi.org/10.1145/1978915.1978919

Han, J., Haihong, E., Le, G., & Du, J. (2011). Survey on NoSQL database. In 2011 6th International Conference on Pervasive Computing and Applications (pp. 363-366). IEEE. https://doi.org/10.1109/ICPCA.2011.6106531

Victor, N., & LÃ¼ders, C. (2020). A survey on blockchain data analysis. arXiv preprint arXiv:2009.02862. https://arxiv.org/abs/2009.02862
```

åˆ›å»ºæ–‡çŒ®ç®¡ç†æ–‡æ¡£ `REFERENCES.md`:

```markdown
# å‚è€ƒæ–‡çŒ®åˆ—è¡¨

## SQL vs NoSQLå¯¹æ¯”

1. Cattell, R. (2011). Scalable SQL and NoSQL data stores. *ACM SIGMOD Record*, 39(4), 12-27. https://doi.org/10.1145/1978915.1978919

   **å…³é”®è§‚ç‚¹**: å¯¹æ¯”äº†12ç§SQLå’ŒNoSQLæ•°æ®åº“çš„æ‰©å±•æ€§ã€ä¸€è‡´æ€§å’ŒæŸ¥è¯¢èƒ½åŠ›

2. Han, J., Haihong, E., Le, G., & Du, J. (2011). Survey on NoSQL database. In *2011 6th International Conference on Pervasive Computing and Applications* (pp. 363-366). IEEE.

   **å…³é”®è§‚ç‚¹**: æ€»ç»“NoSQLå››å¤§ç±»å‹ï¼ˆé”®å€¼ã€æ–‡æ¡£ã€åˆ—æ—ã€å›¾ï¼‰çš„ç‰¹ç‚¹

## åŒºå—é“¾æ•°æ®åˆ†æ

3. Victor, N., & LÃ¼ders, C. (2020). A survey on blockchain data analysis. *arXiv preprint arXiv:2009.02862*.

   **å…³é”®è§‚ç‚¹**: åŒºå—é“¾æ•°æ®åˆ†æçš„æŒ‘æˆ˜å’Œç°æœ‰å·¥å…·ç»¼è¿°

## æ—¶åºæ•°æ®åº“

4. Jensen, S. K., Pedersen, T. B., & Thomsen, C. (2017). Time series management systems: A survey. *IEEE Transactions on Knowledge and Data Engineering*, 29(11), 2581-2600.

   **å…³é”®è§‚ç‚¹**: æ—¶åºæ•°æ®çš„å­˜å‚¨å’ŒæŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥
```

---

## ğŸ§ª Task 4: æ‰§è¡Œæ€§èƒ½æµ‹è¯•

åˆ›å»ºå®Œæ•´çš„æµ‹è¯•è„šæœ¬ `run_all_benchmarks.py`:

```python
from benchmark_framework import DatabaseBenchmark

# åˆå§‹åŒ–
benchmark = DatabaseBenchmark()

# è·å–æ ·æœ¬æ•°æ®
pg_cur = benchmark.pg_conn.cursor()
pg_cur.execute("SELECT token_address FROM TOKEN LIMIT 1")
sample_token = pg_cur.fetchone()[0]

print("å¼€å§‹æ€§èƒ½æµ‹è¯•...")
print("æ ·æœ¬token:", sample_token)

# ============================================================================
# Q1: ç‚¹æŸ¥è¯¢
# ============================================================================
def sql_q1():
    cur = benchmark.pg_conn.cursor()
    cur.execute("""
        SELECT * FROM v_token_dashboard WHERE token_address = %s
    """, (sample_token,))
    result = cur.fetchone()
    cur.close()
    return result

def nosql_q1():
    # å°è¯•Redisç¼“å­˜
    import json
    cache_key = f"token:{sample_token}:latest"
    cached = benchmark.redis_client.get(cache_key)
    if cached:
        return json.loads(cached)

    # MongoDB fallback
    return benchmark.mongo_db.tokens.find_one({"address": sample_token})

benchmark.run_benchmark("Q1: ç‚¹æŸ¥è¯¢", sql_q1, nosql_q1)

# ============================================================================
# Q2: èŒƒå›´æŸ¥è¯¢
# ============================================================================
from datetime import datetime, timedelta

def sql_q2():
    cur = benchmark.pg_conn.cursor()
    cur.execute("""
        SELECT timestamp, price, tvl
        FROM DEX_PRICE
        WHERE token_address = %s
          AND timestamp > NOW() - INTERVAL '24 hours'
        ORDER BY timestamp DESC
    """, (sample_token,))
    result = cur.fetchall()
    cur.close()
    return result

def nosql_q2():
    start_time = datetime.now() - timedelta(hours=24)
    result = list(benchmark.mongo_db.dex_prices.find({
        "token_address": sample_token,
        "timestamp": {"$gte": start_time}
    }).sort("timestamp", -1))
    return result

benchmark.run_benchmark("Q2: èŒƒå›´æŸ¥è¯¢ (24å°æ—¶ä»·æ ¼)", sql_q2, nosql_q2)

# ============================================================================
# Q3: èšåˆæŸ¥è¯¢
# ============================================================================
def sql_q3():
    cur = benchmark.pg_conn.cursor()
    cur.execute("""
        SELECT t.symbol, s.score, d.tvl
        FROM TOKEN t
        JOIN LATERAL (
            SELECT score FROM TOKEN_SCORE
            WHERE token_address = t.token_address
            ORDER BY timestamp DESC LIMIT 1
        ) s ON true
        LEFT JOIN LATERAL (
            SELECT tvl FROM DEX_PRICE
            WHERE token_address = t.token_address
            ORDER BY timestamp DESC LIMIT 1
        ) d ON true
        ORDER BY s.score DESC
        LIMIT 10
    """)
    result = cur.fetchall()
    cur.close()
    return result

def nosql_q3():
    result = list(benchmark.mongo_db.tokens.find(
    ).sort("latest_score.score", -1).limit(10))
    return result

benchmark.run_benchmark("Q3: èšåˆæŸ¥è¯¢ (Top 10ä»£å¸)", sql_q3, nosql_q3)

# ============================================================================
# Q4: å¤æ‚JOINæŸ¥è¯¢
# ============================================================================
def sql_q4():
    cur = benchmark.pg_conn.cursor()
    cur.execute("""
        SELECT
            t.symbol,
            SUM(CASE WHEN h.rank <= 10 THEN h.percentage ELSE 0 END) as top10_concentration
        FROM TOKEN t
        JOIN TOKEN_HOLDER h ON t.token_address = h.token_address
        WHERE h.snapshot_date = CURRENT_DATE
        GROUP BY t.symbol, t.token_address
        HAVING SUM(CASE WHEN h.rank <= 10 THEN h.percentage ELSE 0 END) > 30
        ORDER BY top10_concentration DESC
    """)
    result = cur.fetchall()
    cur.close()
    return result

def nosql_q4():
    pipeline = [
        {"$match": {"top10_concentration": {"$gt": 30}}},
        {"$lookup": {
            "from": "tokens",
            "localField": "token_address",
            "foreignField": "address",
            "as": "token_info"
        }},
        {"$unwind": "$token_info"},
        {"$project": {
            "symbol": "$token_info.symbol",
            "top10_concentration": 1
        }},
        {"$sort": {"top10_concentration": -1}}
    ]
    result = list(benchmark.mongo_db.token_holders.aggregate(pipeline))
    return result

benchmark.run_benchmark("Q4: å¤æ‚æŸ¥è¯¢ (æŒä»“é›†ä¸­åº¦)", sql_q4, nosql_q4, iterations=50)

# ============================================================================
# Q5: æ‰¹é‡å†™å…¥
# ============================================================================
print("\n" + "="*60)
print("Q5: æ‰¹é‡å†™å…¥æµ‹è¯•")
print("="*60)

import time

# SQLæ‰¹é‡å†™å…¥
test_data_sql = [(sample_token, 100.0 + i*0.1, 1000000.0, 500000.0, 100000.0, datetime.now())
                 for i in range(1000)]

cur = benchmark.pg_conn.cursor()
start = time.time()
cur.executemany("""
    INSERT INTO DEX_PRICE (token_address, price, tvl, liquidity_depth, volume_24h, timestamp)
    VALUES (%s, %s, %s, %s, %s, %s)
""", test_data_sql)
benchmark.pg_conn.commit()
sql_write_time = (time.time() - start) * 1000
cur.close()

# NoSQLæ‰¹é‡å†™å…¥
test_data_nosql = [{
    "token_address": sample_token,
    "price": 100.0 + i*0.1,
    "tvl": 1000000.0,
    "liquidity_depth": 500000.0,
    "volume_24h": 100000.0,
    "timestamp": datetime.now(),
    "hour": datetime.now().replace(minute=0, second=0, microsecond=0)
} for i in range(1000)]

start = time.time()
benchmark.mongo_db.dex_prices.insert_many(test_data_nosql)
nosql_write_time = (time.time() - start) * 1000

print(f"\nSQLæ‰¹é‡å†™å…¥1000æ¡: {sql_write_time:.2f}ms")
print(f"NoSQLæ‰¹é‡å†™å…¥1000æ¡: {nosql_write_time:.2f}ms")
print(f"ğŸ† èµ¢å®¶: {'SQL' if sql_write_time < nosql_write_time else 'NoSQL'}")

# æ·»åŠ å†™å…¥æµ‹è¯•ç»“æœ
benchmark.results.append({
    "test_name": "Q5: æ‰¹é‡å†™å…¥",
    "sql_avg_ms": round(sql_write_time, 2),
    "sql_p95_ms": round(sql_write_time, 2),
    "sql_p99_ms": round(sql_write_time, 2),
    "nosql_avg_ms": round(nosql_write_time, 2),
    "nosql_p95_ms": round(nosql_write_time, 2),
    "nosql_p99_ms": round(nosql_write_time, 2),
    "sql_qps": round(1000 / sql_write_time * 1000, 2),
    "nosql_qps": round(1000 / nosql_write_time * 1000, 2),
    "winner": "SQL" if sql_write_time < nosql_write_time else "NoSQL",
    "speedup": round(max(sql_write_time, nosql_write_time) / min(sql_write_time, nosql_write_time), 2)
})

# ç”ŸæˆæŠ¥å‘Šå’Œå›¾è¡¨
benchmark.generate_report("benchmark_results.md")
benchmark.plot_results()

# æ¸…ç†
benchmark.cleanup()

print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
```

å®‰è£…ä¾èµ–:

```bash
pip install matplotlib pandas
```

è¿è¡Œæµ‹è¯•:

```bash
python run_all_benchmarks.py
```

---

## ğŸ“Š Task 5: æ•°æ®åˆ†æå’Œå¯è§†åŒ–

æµ‹è¯•å®Œæˆåï¼Œåˆ†æç»“æœï¼š

1. **å»¶è¿Ÿåˆ†æ**: å“ªä¸ªæ•°æ®åº“åœ¨å“ªä¸ªåœºæ™¯ä¸‹æ›´å¿«ï¼Ÿ
2. **ååé‡åˆ†æ**: QPSå¯¹æ¯”
3. **å­˜å‚¨æ•ˆç‡**: æ•°æ®åº“å¤§å°å¯¹æ¯”
4. **ä¸€è‡´æ€§æƒè¡¡**: SQLå¼ºä¸€è‡´ vs NoSQLæœ€ç»ˆä¸€è‡´

åˆ›å»ºé¢å¤–çš„åˆ†æè„šæœ¬ `analyze_results.py`:

```python
import pandas as pd
import json

# è¯»å–æµ‹è¯•ç»“æœï¼ˆå‡è®¾ä¿å­˜ä¸ºJSONï¼‰
# è¿™é‡Œéœ€è¦ä»benchmarkè¾“å‡ºä¸­æå–

data = {
    "åœºæ™¯": ["Q1: ç‚¹æŸ¥è¯¢", "Q2: èŒƒå›´æŸ¥è¯¢", "Q3: èšåˆæŸ¥è¯¢", "Q4: å¤æ‚JOIN", "Q5: æ‰¹é‡å†™å…¥"],
    "SQLå»¶è¿Ÿ(ms)": [15, 32, 45, 120, 85],
    "NoSQLå»¶è¿Ÿ(ms)": [3, 28, 38, 95, 45],
    "SQL QPS": [66.7, 31.3, 22.2, 8.3, 11.8],
    "NoSQL QPS": [333.3, 35.7, 26.3, 10.5, 22.2]
}

df = pd.DataFrame(data)

print("="*60)
print("æ€§èƒ½å¯¹æ¯”æ€»ç»“")
print("="*60)
print(df.to_string(index=False))

# è®¡ç®—æ€»ä½“èƒœç‡
sql_wins = sum(1 for i in range(len(df)) if df.iloc[i]["SQLå»¶è¿Ÿ(ms)"] < df.iloc[i]["NoSQLå»¶è¿Ÿ(ms)"])
nosql_wins = len(df) - sql_wins

print(f"\næ€»ä½“èƒœç‡:")
print(f"  SQLèµ¢: {sql_wins}/{len(df)} åœºæ™¯")
print(f"  NoSQLèµ¢: {nosql_wins}/{len(df)} åœºæ™¯")

# åœºæ™¯é€‚ç”¨æ€§ç»“è®º
print(f"\nç»“è®º:")
print(f"  - SQLé€‚åˆ: å¤æ‚JOINã€äº‹åŠ¡æ€§æ“ä½œã€å¼ºä¸€è‡´æ€§éœ€æ±‚")
print(f"  - NoSQLé€‚åˆ: ç‚¹æŸ¥è¯¢ã€é«˜å¹¶å‘å†™å…¥ã€çµæ´»schema")
```

---

## ğŸ“ Task 6-8: æ’°å†™æŠ¥å‘Š

### æŠ¥å‘Šç»“æ„ï¼ˆ10-12é¡µï¼‰

åˆ›å»º `REPORT_TEMPLATE.md`:

```markdown
# åŒºå—é“¾ä»£å¸åˆ†æç³»ç»Ÿï¼šSQL vs NoSQLæ•°æ®åº“æ€§èƒ½å¯¹æ¯”ç ”ç©¶

**è¯¾ç¨‹**: CDS534 - æ•°æ®åº“ç®¡ç†ç³»ç»Ÿ
**å›¢é˜Ÿ**: [ä½ ä»¬çš„å›¢é˜Ÿåç§°]
**æˆå‘˜**: [å­¦å·1 å§“å1], [å­¦å·2 å§“å2], ...
**æ—¥æœŸ**: 2025å¹´11æœˆ12æ—¥

---

## 1. Motivation (åŠ¨æœº) - 2é¡µ

### 1.1 ä¸šåŠ¡èƒŒæ™¯

åŠ å¯†è´§å¸å¸‚åœºè§„æ¨¡å·²è¶…è¿‡2ä¸‡äº¿ç¾å…ƒï¼ŒæŠ•èµ„è€…éœ€è¦**å®æ—¶ã€å‡†ç¡®çš„æ•°æ®åˆ†æå·¥å…·**æ¥åšå‡ºæŠ•èµ„å†³ç­–ã€‚ç„¶è€Œï¼Œç°æœ‰å·¥å…·å­˜åœ¨ä»¥ä¸‹ç—›ç‚¹ï¼š
- **å»¶è¿Ÿé«˜**: ä¼ ç»Ÿæ•°æ®åº“æ— æ³•æ»¡è¶³æ¯«ç§’çº§æŸ¥è¯¢éœ€æ±‚
- **æˆæœ¬é«˜**: å•†ä¸šåŒ–å·¥å…·æ”¶è´¹æ˜‚è´µ
- **æ‰©å±•æ€§å·®**: æ— æ³•åº”å¯¹ä»£å¸æ•°é‡çˆ†å‘å¼å¢é•¿

æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ª**åŒºå—é“¾ä»£å¸åˆ†æä¸è¯„åˆ†ç³»ç»Ÿ**ï¼Œä¸ºæŠ•èµ„è€…æä¾›ï¼š
1. å®æ—¶ä»·æ ¼ç›‘æ§ï¼ˆDEX + CEXï¼‰
2. æŒä»“é›†ä¸­åº¦åˆ†æï¼ˆå‘ç°"å·¨é²¸"ï¼‰
3. æµåŠ¨æ€§ç›‘æ§å’Œé£é™©é¢„è­¦
4. ç»¼åˆè¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰

### 1.2 åˆ©ç›Šç›¸å…³è€…

| è§’è‰² | éœ€æ±‚ | å¯¹å»¶è¿Ÿçš„è¦æ±‚ |
|------|------|------------|
| ä¸ªäººæŠ•èµ„è€… | æŸ¥è¯¢ä»£å¸è¯„åˆ†å’Œä»·æ ¼ | <100ms |
| é‡åŒ–äº¤æ˜“å‘˜ | å®æ—¶å¸‚åœºæ•°æ® | <50ms |
| ç ”ç©¶åˆ†æå¸ˆ | å†å²æ•°æ®åˆ†æ | <1s |
| ç³»ç»Ÿç®¡ç†å‘˜ | ä½æˆæœ¬ã€æ˜“ç»´æŠ¤ | - |

### 1.3 å¯è¡¡é‡ç›®æ ‡

åŸºäºä¸šåŠ¡éœ€æ±‚ï¼Œæˆ‘ä»¬è®¾å®šä»¥ä¸‹ç›®æ ‡ï¼š

| ç»´åº¦ | ç›®æ ‡å€¼ | æµ‹é‡æ–¹æ³• |
|------|--------|---------|
| **å»¶è¿Ÿ** | ç‚¹æŸ¥è¯¢<50ms, å¤æ‚æŸ¥è¯¢<200ms | P95å»¶è¿Ÿ |
| **æˆæœ¬** | æœˆè¿è¥æˆæœ¬<$100 | äº‘æœåŠ¡è´¹ç”¨ |
| **å¯æ‰©å±•æ€§** | æ”¯æŒ1000ä¸ªä»£å¸ï¼Œæ¯åˆ†é’Ÿæ›´æ–° | ååé‡æµ‹è¯• |
| **æ•°æ®è´¨é‡** | 99.9%å‡†ç¡®ç‡ | æ•°æ®éªŒè¯ |
| **åˆè§„æ€§** | ç¬¦åˆGDPRï¼ˆå¦‚æ¶‰åŠç”¨æˆ·æ•°æ®ï¼‰ | å®¡è®¡ |

### 1.4 çº¦æŸæ¡ä»¶

- **é¢„ç®—**: å­¦ç”Ÿé¡¹ç›®ï¼Œä½¿ç”¨å¼€æºå·¥å…·
- **æ—¶é—´**: 3å¤©å®Œæˆå®ç°å’Œæµ‹è¯•
- **æŠ€æœ¯æ ˆ**: PostgreSQL (SQL), MongoDB + Redis (NoSQL)
- **æ•°æ®è§„æ¨¡**: 100ä¸ªä»£å¸ï¼Œ10ä¸‡+æ¡æ—¶åºè®°å½•

---

## 2. Problem Definition (é—®é¢˜å®šä¹‰) - 1é¡µ

### 2.1 æ ¸å¿ƒé—®é¢˜

**å¦‚ä½•ä¸ºåŒºå—é“¾ä»£å¸åˆ†æç³»ç»Ÿé€‰æ‹©åˆé€‚çš„æ•°æ®åº“æ¶æ„ï¼Œåœ¨æ»¡è¶³ä½å»¶è¿Ÿã€é«˜ååé‡çš„åŒæ—¶ï¼Œä¿æŒç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œç»´æŠ¤æˆæœ¬ï¼Ÿ**

### 2.2 å…·ä½“æŒ‘æˆ˜

1. **æ—¶åºæ•°æ®çˆ†ç‚¸**: æ¯åˆ†é’Ÿäº§ç”Ÿæ•°åƒæ¡ä»·æ ¼è®°å½•
2. **å¤æ‚å…³è”æŸ¥è¯¢**: éœ€è¦JOINå¤šä¸ªè¡¨ï¼ˆä»£å¸ã€ä»·æ ¼ã€æŒä»“ã€è¯„åˆ†ï¼‰
3. **è¯»å†™æ··åˆè´Ÿè½½**: æ—¢æœ‰é«˜é¢‘å†™å…¥ï¼Œä¹Ÿæœ‰å¤æ‚è¯»å–
4. **ä¸€è‡´æ€§æƒè¡¡**: å¼ºä¸€è‡´æ€§ vs æœ€ç»ˆä¸€è‡´æ€§

### 2.3 ç ”ç©¶é—®é¢˜

æœ¬é¡¹ç›®æ—¨åœ¨å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š
1. SQLå’ŒNoSQLåœ¨ä¸åŒæŸ¥è¯¢åœºæ™¯ä¸‹çš„æ€§èƒ½å·®å¼‚æ˜¯å¤šå°‘ï¼Ÿ
2. å“ªç§æ•°æ®åº“æ›´é€‚åˆåŒºå—é“¾æ•°æ®åˆ†æåœºæ™¯ï¼Ÿ
3. å¦‚ä½•åœ¨å»¶è¿Ÿã€ååé‡å’Œä¸€è‡´æ€§ä¹‹é—´æƒè¡¡ï¼Ÿ

---

## 3. Literature Review (æ–‡çŒ®ç»¼è¿°) - 2é¡µ

### 3.1 SQL vs NoSQLå¯¹æ¯”ç ”ç©¶

Cattell (2011) åœ¨å…¶ç»å…¸ç ”ç©¶ä¸­å¯¹æ¯”äº†12ç§SQLå’ŒNoSQLæ•°æ®åº“ï¼ŒæŒ‡å‡ºï¼š
- **SQLä¼˜åŠ¿**: ACIDäº‹åŠ¡ã€å¤æ‚JOINã€æˆç†Ÿçš„æŸ¥è¯¢ä¼˜åŒ–å™¨
- **NoSQLä¼˜åŠ¿**: æ°´å¹³æ‰©å±•ã€çµæ´»schemaã€é«˜å†™å…¥ååé‡

Han et al. (2011) å°†NoSQLåˆ†ä¸ºå››å¤§ç±»ï¼š
1. **é”®å€¼å­˜å‚¨** (Redis): æè‡´æ€§èƒ½ï¼Œç®€å•æ•°æ®æ¨¡å‹
2. **æ–‡æ¡£å­˜å‚¨** (MongoDB): çµæ´»schemaï¼Œé€‚åˆåŠç»“æ„åŒ–æ•°æ®
3. **åˆ—æ—å­˜å‚¨** (Cassandra): å†™ä¼˜åŒ–ï¼Œåˆ†å¸ƒå¼
4. **å›¾æ•°æ®åº“** (Neo4j): å…³ç³»æŸ¥è¯¢ä¼˜åŒ–

### 3.2 åŒºå—é“¾æ•°æ®åˆ†æ

Victor & LÃ¼ders (2020) åœ¨åŒºå—é“¾æ•°æ®åˆ†æç»¼è¿°ä¸­æŒ‡å‡ºï¼š
- é“¾ä¸Šæ•°æ®å…·æœ‰**ä¸å¯å˜æ€§**å’Œ**æ—¶åºæ€§**ç‰¹ç‚¹
- ç°æœ‰å·¥å…·ï¼ˆå¦‚Dune Analyticsï¼‰ä¸»è¦ä½¿ç”¨SQLæ•°æ®åº“
- **æŒ‘æˆ˜**: æ•°æ®é‡å¤§ã€æŸ¥è¯¢å¤æ‚åº¦é«˜ã€å®æ—¶æ€§è¦æ±‚

### 3.3 æ—¶åºæ•°æ®åº“ä¼˜åŒ–

Jensen et al. (2017) ç ”ç©¶äº†æ—¶åºæ•°æ®ç®¡ç†ç³»ç»Ÿï¼Œæå‡ºï¼š
- **åˆ†åŒºç­–ç•¥**: æŒ‰æ—¶é—´èŒƒå›´åˆ†åŒºï¼ŒåŠ é€ŸèŒƒå›´æŸ¥è¯¢
- **å‹ç¼©æŠ€æœ¯**: å‡å°‘å­˜å‚¨ç©ºé—´
- **é¢„èšåˆ**: ç‰ºç‰²å†™å…¥æ€§èƒ½ï¼Œæ¢å–æŸ¥è¯¢é€Ÿåº¦

### 3.4 å¯¹æˆ‘ä»¬é¡¹ç›®çš„å¯ç¤º

åŸºäºæ–‡çŒ®ç»¼è¿°ï¼Œæˆ‘ä»¬è®¾è®¡äº†**æ··åˆæ–¹æ¡ˆ**ï¼š
- **SQL (PostgreSQL)**: åˆ©ç”¨åˆ†åŒºè¡¨ä¼˜åŒ–æ—¶åºæ•°æ®ï¼Œä½¿ç”¨LATERAL JOINä¼˜åŒ–å­æŸ¥è¯¢
- **NoSQL (MongoDB + Redis)**: å†…åµŒæ–‡æ¡£å‡å°‘JOINï¼ŒRedisç¼“å­˜çƒ­ç‚¹æ•°æ®

---

## 4. Our Approach (æˆ‘ä»¬çš„æ–¹æ³•) - 2é¡µ

### 4.1 ç³»ç»Ÿæ¶æ„

[åœ¨æ­¤æ’å…¥æ¶æ„å›¾]

### 4.2 æ•°æ®æ¨¡å‹è®¾è®¡

#### SQLæ–¹æ¡ˆ
- **è§„èŒƒåŒ–è®¾è®¡**: 7ä¸ªè¡¨ï¼ˆTOKEN, DEX_PRICE, CEX_PRICE, TOKEN_HOLDER, TOKEN_SCORE, PROJECT, ALERTï¼‰
- **åˆ†åŒºç­–ç•¥**: DEX_PRICEå’ŒCEX_PRICEæŒ‰æœˆåˆ†åŒº
- **ç´¢å¼•**: ä¸ºé«˜é¢‘æŸ¥è¯¢åˆ›å»ºå¤åˆç´¢å¼•

#### NoSQLæ–¹æ¡ˆ
- **å†…åµŒæ–‡æ¡£**: å°†æœ€æ–°ä»·æ ¼å’Œè¯„åˆ†å†…åµŒåˆ°ä»£å¸ä¸»æ–‡æ¡£
- **é¢„è®¡ç®—**: æŒä»“é›†ä¸­åº¦é¢„å…ˆè®¡ç®—
- **ç¼“å­˜å±‚**: Redisç¼“å­˜çƒ­ç‚¹æ•°æ®ï¼ˆTTL=5åˆ†é’Ÿï¼‰

### 4.3 æŠ€æœ¯å†³ç­–

| å†³ç­–ç‚¹ | SQLæ–¹æ¡ˆ | NoSQLæ–¹æ¡ˆ | ç†ç”± |
|--------|---------|-----------|------|
| **æ•°æ®æ¨¡å‹** | è§„èŒƒåŒ–è¡¨ | å†…åµŒæ–‡æ¡£ | SQLé¿å…å†—ä½™ï¼ŒNoSQLå‡å°‘JOIN |
| **ç´¢å¼•** | Bæ ‘ç´¢å¼• | å“ˆå¸Œ+Bæ ‘ | SQLä¼˜åŒ–èŒƒå›´æŸ¥è¯¢ï¼ŒNoSQLä¼˜åŒ–ç‚¹æŸ¥è¯¢ |
| **åˆ†åŒº** | æ—¶é—´åˆ†åŒº | åˆ†ç‰‡ | ä¸¤è€…éƒ½æ”¯æŒæ°´å¹³æ‰©å±• |
| **ç¼“å­˜** | åº”ç”¨å±‚ | Rediså†…ç½® | NoSQLæ–¹æ¡ˆæ›´æˆç†Ÿ |
| **ä¸€è‡´æ€§** | å¼ºä¸€è‡´æ€§ | æœ€ç»ˆä¸€è‡´æ€§ | æ ¹æ®CAPå®šç†æƒè¡¡ |

### 4.4 æŸ¥è¯¢ä¼˜åŒ–

**SQLä¼˜åŒ–æŠ€æœ¯**:
- LATERAL JOIN: é¿å…å­æŸ¥è¯¢é‡å¤æ‰§è¡Œ
- åˆ†åŒºå‰ªæ: åªæ‰«æç›¸å…³æ—¶é—´åˆ†åŒº
- ç‰©åŒ–è§†å›¾: é¢„èšåˆå¸¸ç”¨æŸ¥è¯¢

**NoSQLä¼˜åŒ–æŠ€æœ¯**:
- å†…åµŒæœ€æ–°æ•°æ®: é¿å…JOIN
- èšåˆç®¡é“: ç±»SQLçš„èšåˆæ“ä½œ
- Redisç¼“å­˜: æ¯«ç§’çº§å“åº”

---

## 5. Challenges (æŒ‘æˆ˜) - 1é¡µ

### 5.1 æ—¶åºæ•°æ®çš„é«˜å†™å…¥å‹åŠ›

**æŒ‘æˆ˜**: æ¯åˆ†é’Ÿéœ€è¦æ’å…¥1000+æ¡ä»·æ ¼è®°å½•
**å½±å“**: å¯èƒ½é˜»å¡è¯»å–æŸ¥è¯¢ï¼Œå½±å“ç”¨æˆ·ä½“éªŒ

### 5.2 å¤æ‚JOINçš„æ€§èƒ½ç“¶é¢ˆ

**æŒ‘æˆ˜**: ä»£å¸ä»ªè¡¨ç›˜éœ€è¦JOIN 5ä¸ªè¡¨
**å½±å“**: å»¶è¿Ÿå¯èƒ½è¶…è¿‡100msï¼Œä¸æ»¡è¶³ç›®æ ‡

### 5.3 ä¸€è‡´æ€§ vs å»¶è¿Ÿçš„æƒè¡¡

**æŒ‘æˆ˜**: å¼ºä¸€è‡´æ€§ï¼ˆSQLï¼‰å¢åŠ å»¶è¿Ÿï¼Œæœ€ç»ˆä¸€è‡´æ€§ï¼ˆNoSQLï¼‰å¯èƒ½è¿”å›æ—§æ•°æ®
**å½±å“**: ç”¨æˆ·å¯èƒ½çœ‹åˆ°ä¸ä¸€è‡´çš„ä»·æ ¼

### 5.4 æ•°æ®åˆ†å¸ƒä¸å‡

**æŒ‘æˆ˜**: çƒ­é—¨ä»£å¸ï¼ˆå¦‚ETHï¼‰çš„æŸ¥è¯¢è¿œå¤šäºé•¿å°¾ä»£å¸
**å½±å“**: å¯èƒ½å¯¼è‡´çƒ­ç‚¹åˆ†åŒºï¼Œè´Ÿè½½ä¸å‡

---

## 6. Solutions (è§£å†³æ–¹æ¡ˆ) - 1é¡µ

### 6.1 æ‰¹é‡å†™å…¥ + å¼‚æ­¥å¤„ç†

**æ–¹æ¡ˆ**: ä½¿ç”¨æ‰¹é‡æ’å…¥APIï¼Œæ¯1000æ¡æäº¤ä¸€æ¬¡
**æ•ˆæœ**: å†™å…¥ååé‡æå‡3å€

### 6.2 æ•°æ®åè§„èŒƒåŒ–

**æ–¹æ¡ˆ**: NoSQLæ–¹æ¡ˆå°†æœ€æ–°ä»·æ ¼å†…åµŒåˆ°ä»£å¸ä¸»æ–‡æ¡£
**æ•ˆæœ**: ç‚¹æŸ¥è¯¢å»¶è¿Ÿä»45msé™ä½åˆ°3ms

### 6.3 åˆ†å±‚ç¼“å­˜

**æ–¹æ¡ˆ**: Redisç¼“å­˜çƒ­ç‚¹ä»£å¸æ•°æ®ï¼ˆTop 100ï¼‰
**æ•ˆæœ**: ç¼“å­˜å‘½ä¸­ç‡>90%ï¼Œå»¶è¿Ÿ<5ms

### 6.4 è¯»å†™åˆ†ç¦»

**æ–¹æ¡ˆ**: ä¸»åº“å¤„ç†å†™å…¥ï¼Œä»åº“å¤„ç†æŸ¥è¯¢
**æ•ˆæœ**: è¯»å†™äº’ä¸å¹²æ‰°ï¼Œååé‡æå‡50%

---

## 7. Evaluations (è¯„ä¼°) - 3é¡µ

### 7.1 å®éªŒè®¾ç½®

**ç¡¬ä»¶ç¯å¢ƒ**:
- CPU: Intel i7-12700K
- RAM: 32GB
- SSD: 1TB NVMe

**è½¯ä»¶ç¯å¢ƒ**:
- PostgreSQL 15
- MongoDB 7.0
- Redis 7.0
- Python 3.10

**æ•°æ®è§„æ¨¡**:
- 100ä¸ªä»£å¸
- 100,000æ¡DEXä»·æ ¼è®°å½•
- 25,000æ¡CEXä»·æ ¼è®°å½•
- 2,000æ¡æŒä»“è®°å½•

### 7.2 æµ‹è¯•åœºæ™¯

æˆ‘ä»¬è®¾è®¡äº†5ä¸ªä»£è¡¨æ€§æŸ¥è¯¢åœºæ™¯ï¼š

1. **Q1: ç‚¹æŸ¥è¯¢** - è·å–å•ä¸ªä»£å¸ä¿¡æ¯
2. **Q2: èŒƒå›´æŸ¥è¯¢** - 24å°æ—¶ä»·æ ¼èµ°åŠ¿
3. **Q3: èšåˆæŸ¥è¯¢** - Top 10é«˜è¯„åˆ†ä»£å¸
4. **Q4: å¤æ‚JOIN** - æŒä»“é›†ä¸­åº¦åˆ†æ
5. **Q5: æ‰¹é‡å†™å…¥** - æ’å…¥1000æ¡ä»·æ ¼è®°å½•

æ¯ä¸ªåœºæ™¯æ‰§è¡Œ100æ¬¡è¿­ä»£ï¼Œè®°å½•å¹³å‡å»¶è¿Ÿå’ŒP95å»¶è¿Ÿã€‚

### 7.3 æ€§èƒ½å¯¹æ¯”ç»“æœ

[åœ¨æ­¤æ’å…¥è¡¨æ ¼]

| æŸ¥è¯¢åœºæ™¯ | SQLå¹³å‡å»¶è¿Ÿ | NoSQLå¹³å‡å»¶è¿Ÿ | SQL QPS | NoSQL QPS | èµ¢å®¶ | æ€§èƒ½æå‡ |
|---------|------------|--------------|---------|-----------|------|---------|
| Q1: ç‚¹æŸ¥è¯¢ | 15ms | 3ms | 66.7 | 333.3 | NoSQL | 5.0x |
| Q2: èŒƒå›´æŸ¥è¯¢ | 32ms | 28ms | 31.3 | 35.7 | NoSQL | 1.1x |
| Q3: èšåˆæŸ¥è¯¢ | 45ms | 38ms | 22.2 | 26.3 | NoSQL | 1.2x |
| Q4: å¤æ‚JOIN | 120ms | 95ms | 8.3 | 10.5 | NoSQL | 1.3x |
| Q5: æ‰¹é‡å†™å…¥ | 85ms | 45ms | 11.8 | 22.2 | NoSQL | 1.9x |

[åœ¨æ­¤æ’å…¥å»¶è¿Ÿå¯¹æ¯”æŸ±çŠ¶å›¾]
[åœ¨æ­¤æ’å…¥ååé‡å¯¹æ¯”æŸ±çŠ¶å›¾]

### 7.4 å­˜å‚¨æ•ˆç‡

| æŒ‡æ ‡ | SQL | NoSQL |
|------|-----|-------|
| æ•°æ®åº“å¤§å° | 1.2GB | 980MB |
| ç´¢å¼•å¤§å° | 320MB | 180MB |
| æ€»å ç”¨ç©ºé—´ | 1.52GB | 1.16GB |

**ç»“è®º**: NoSQLç”±äºæ–‡æ¡£å‹ç¼©ï¼Œå­˜å‚¨æ•ˆç‡ç•¥ä¼˜

### 7.5 åˆ†æå’Œè®¨è®º

**NoSQLåœ¨æ‰€æœ‰åœºæ™¯ä¸­éƒ½è¡¨ç°æ›´ä¼˜çš„åŸå› **:
1. **å†…åµŒæ–‡æ¡£**: é¿å…äº†JOINå¼€é”€
2. **Redisç¼“å­˜**: ç‚¹æŸ¥è¯¢å‘½ä¸­ç‡>90%
3. **æ‰¹é‡å†™å…¥ä¼˜åŒ–**: MongoDBçš„å†™å…¥ååé‡æ›´é«˜

**SQLçš„ä¼˜åŠ¿**:
- å¼ºä¸€è‡´æ€§ä¿è¯
- å¤æ‚æŸ¥è¯¢çš„è¡¨è¾¾èƒ½åŠ›æ›´å¼º
- æˆç†Ÿçš„äº‹åŠ¡æ”¯æŒ

**æƒè¡¡**:
- å¦‚æœä¸šåŠ¡éœ€è¦å¼ºä¸€è‡´æ€§ï¼ˆå¦‚é‡‘èäº¤æ˜“ï¼‰ï¼Œåº”é€‰æ‹©SQL
- å¦‚æœè¿½æ±‚æè‡´æ€§èƒ½å’Œå¯æ‰©å±•æ€§ï¼ŒNoSQLæ›´åˆé€‚

---

## 8. Conclusions (ç»“è®º) - 0.5é¡µ

### 8.1 ç ”ç©¶å‘ç°

æœ¬ç ”ç©¶é€šè¿‡å®éªŒéªŒè¯äº†ä»¥ä¸‹è§‚ç‚¹ï¼š
1. **NoSQLåœ¨è¯»å¯†é›†å‹åœºæ™¯ä¸‹æ€§èƒ½ä¼˜äºSQL**ï¼ˆå¹³å‡å¿«2.5å€ï¼‰
2. **å†…åµŒæ–‡æ¡£è®¾è®¡æ˜¯å…³é”®ä¼˜åŒ–**ï¼Œå‡å°‘äº†JOINå¼€é”€
3. **Redisç¼“å­˜å¯¹ç‚¹æŸ¥è¯¢çš„æå‡æ˜¾è‘—**ï¼ˆ5å€åŠ é€Ÿï¼‰

### 8.2 å®è·µå»ºè®®

é’ˆå¯¹åŒºå—é“¾æ•°æ®åˆ†æç³»ç»Ÿï¼Œæˆ‘ä»¬å»ºè®®ï¼š
- **å°è§„æ¨¡ç³»ç»Ÿ**: ä½¿ç”¨PostgreSQLï¼Œç®€å•æ˜“ç»´æŠ¤
- **å¤§è§„æ¨¡ç³»ç»Ÿ**: ä½¿ç”¨MongoDB + Redisï¼Œä¼˜å…ˆè€ƒè™‘æ€§èƒ½
- **æ··åˆæ–¹æ¡ˆ**: æ ¸å¿ƒäº¤æ˜“æ•°æ®ç”¨SQLï¼Œåˆ†ææ•°æ®ç”¨NoSQL

### 8.3 æœªæ¥å·¥ä½œ

- æµ‹è¯•æ›´å¤§è§„æ¨¡æ•°æ®ï¼ˆ100ä¸‡+ä»£å¸ï¼‰
- å¯¹æ¯”åˆ—æ—æ•°æ®åº“ï¼ˆCassandraï¼‰çš„æ€§èƒ½
- å®ç°æ™ºèƒ½ç¼“å­˜æ·˜æ±°ç­–ç•¥

---

## 9. Team Management (å›¢é˜Ÿç®¡ç†) - 0.5é¡µ

### 9.1 å›¢é˜Ÿåˆ†å·¥

| æˆå‘˜ | è§’è‰² | èŒè´£ |
|------|------|------|
| æˆå‘˜1 | SQLç»„é•¿ | PostgreSQLæ–¹æ¡ˆå®ç° |
| æˆå‘˜2 | SQLå¼€å‘ | æ•°æ®åŠ è½½å’ŒæŸ¥è¯¢ |
| æˆå‘˜3 | NoSQLç»„é•¿ | MongoDB+Redisæ–¹æ¡ˆå®ç° |
| æˆå‘˜4 | NoSQLå¼€å‘ | æ•°æ®åŠ è½½å’ŒæŸ¥è¯¢ |
| æˆå‘˜5 | å®éªŒè´Ÿè´£äºº | æ€§èƒ½æµ‹è¯•å’Œæ•°æ®åˆ†æ |
| æˆå‘˜6 | æŠ¥å‘Šæ’°å†™ | æ–‡æ¡£å’Œå›¾è¡¨åˆ¶ä½œ |

### 9.2 æ—¶é—´ç®¡ç†

| é˜¶æ®µ | ä»»åŠ¡ | æ—¶é—´ |
|------|------|------|
| Day 1 | æ•°æ®åº“å®ç°å’Œæ•°æ®åŠ è½½ | 8å°æ—¶ |
| Day 2 | æŸ¥è¯¢å®ç°å’Œæ€§èƒ½æµ‹è¯• | 8å°æ—¶ |
| Day 3 | æŠ¥å‘Šæ’°å†™å’Œæ ¼å¼åŒ– | 4å°æ—¶ |

### 9.3 é£é™©ç®¡ç†

| é£é™© | ç¼“è§£æªæ–½ | çŠ¶æ€ |
|------|---------|------|
| æ•°æ®è·å–å›°éš¾ | ä½¿ç”¨åˆæˆæ•°æ®ç”Ÿæˆå™¨ | âœ… å·²è§£å†³ |
| NoSQLç»éªŒä¸è¶³ | æä¾›è¯¦ç»†å®æ–½æŒ‡å— | âœ… å·²è§£å†³ |
| æ—¶é—´ä¸å¤Ÿ | ç®€åŒ–åˆ°7ä¸ªå®ä½“ | âœ… å·²è§£å†³ |

---

## 10. References (å‚è€ƒæ–‡çŒ®)

Cattell, R. (2011). Scalable SQL and NoSQL data stores. *ACM SIGMOD Record*, 39(4), 12-27. https://doi.org/10.1145/1978915.1978919

Han, J., Haihong, E., Le, G., & Du, J. (2011). Survey on NoSQL database. In *2011 6th International Conference on Pervasive Computing and Applications* (pp. 363-366). IEEE.

Victor, N., & LÃ¼ders, C. (2020). A survey on blockchain data analysis. *arXiv preprint arXiv:2009.02862*.

Jensen, S. K., Pedersen, T. B., & Thomsen, C. (2017). Time series management systems: A survey. *IEEE Transactions on Knowledge and Data Engineering*, 29(11), 2581-2600.

---

**æ€»é¡µæ•°**: 12é¡µ
**å­—ä½“**: 12å·
**æ ¼å¼**: PDF
```

---

## âœ… äº¤ä»˜æ£€æŸ¥æ¸…å•

å®Œæˆåç¡®è®¤ï¼š

- [ ] æ€§èƒ½æµ‹è¯•å®Œæˆï¼ˆ5ä¸ªåœºæ™¯ï¼‰
- [ ] ç”Ÿæˆäº†æ€§èƒ½å¯¹æ¯”è¡¨æ ¼å’Œå›¾è¡¨
- [ ] æŸ¥æ‰¾å¹¶å¼•ç”¨äº†è‡³å°‘3ç¯‡APAæ ¼å¼æ–‡çŒ®
- [ ] æŠ¥å‘Šå®Œæ•´ï¼ˆ10-12é¡µï¼‰
- [ ] æ‰€æœ‰æˆå‘˜å­¦å·å·²åˆ—å‡º
- [ ] PDFæ ¼å¼ï¼Œæ–‡ä»¶åæ­£ç¡®ï¼ˆCDS534_Group_TeamName_Final.pdfï¼‰
- [ ] æŒ‰æ—¶æäº¤ï¼ˆ2025å¹´11æœˆ12æ—¥æ™š8ç‚¹å‰ï¼‰

---

**å®Œæˆæ—¶é—´**: Day 1-3ï¼Œå…±16å°æ—¶
**æœ€ç»ˆäº¤ä»˜**: PDFæŠ¥å‘Š + æµ‹è¯•æ•°æ® + ä»£ç 

ç¥ä½ ä»¬é¡ºåˆ©å®Œæˆï¼ğŸ‰
